# main.py ‚Äî AI Halyava Bot (–∫—É–ø–æ–Ω-–±–æ—Ç —Å Admitad + CityAds + HTML)
# Python 3.13.4 ; aiogram 3.22.0 ; long-polling ; SQLite + APScheduler
import os
import re
import json
import html
import time
import asyncio
import logging
import sqlite3
import threading
import datetime
from typing import Optional, List, Dict, Any
import requests
import feedparser
from bs4 import BeautifulSoup

from aiogram import Bot, Dispatcher, Router, F
from aiogram.client.default import DefaultBotProperties
from aiogram.enums import ParseMode
from aiogram.filters import Command
from aiogram.types import Message
from apscheduler.schedulers.asyncio import AsyncIOScheduler

# ---------- –õ–û–ì–ò ----------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(message)s"
)
log = logging.getLogger(__name__)

# ---------- –ö–û–ù–§–ò–ì ----------
BOT_TOKEN = os.environ.get("BOT_TOKEN", "").strip()
TIMEZONE = os.environ.get("TIMEZONE", "Europe/Moscow")
DB_PATH = os.environ.get("DB_PATH", "/data/halyava.db")

TRIAL_DAYS = int(os.environ.get("TRIAL_DAYS", "3"))
MONTHLY_PRICE_RUB = int(os.environ.get("MONTHLY_PRICE_RUB", "249"))

# Admitad
ADMITAD_ACCESS_TOKEN = os.environ.get("ADMITAD_ACCESS_TOKEN", "").strip()
ADMITAD_CLIENT_ID = os.environ.get("ADMITAD_CLIENT_ID", "").strip()
ADMITAD_CLIENT_SECRET = os.environ.get("ADMITAD_CLIENT_SECRET", "").strip()
ADMITAD_WEBSITE_ID = os.environ.get("ADMITAD_WEBSITE_ID", "").strip()  # –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è /coupons/website

# CityAds
CITYADS_COUPONS_URL = os.environ.get("CITYADS_COUPONS_URL", "").strip()

# –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–º–æ-—Å—Ç—Ä–∞–Ω–∏—Ü—ã –º–∞–≥–∞–∑–∏–Ω–æ–≤
OFFICIAL_PROMO_PAGES = [
    u.strip() for u in os.environ.get("OFFICIAL_PROMO_PAGES", "").split(",") if u.strip()
]

# –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–∞–≥–∞–∑–∏–Ω—ã –†–§ + –º–∞—Ä–∫–µ—Ç—ã + –µ–¥–∞ (—Å–∏–Ω–æ–Ω–∏–º—ã ‚Üí –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π slug)
STORE_ALIASES: Dict[str, str] = {
    # marketplaces
    "ozon": "ozon",
    "–æ–∑–æ–Ω": "ozon",
    "wildberries": "wildberries",
    "–≤–±": "wildberries",
    "wild": "wildberries",
    "wb": "wildberries",
    "—è–Ω–¥–µ–∫—Å –º–∞—Ä–∫–µ—Ç": "yandex_market",
    "—è –º–∞—Ä–∫–µ—Ç": "yandex_market",
    "ym": "yandex_market",
    "aliexpress": "aliexpress",
    "–∞–ª–∏—ç–∫—Å–ø—Ä–µ—Å—Å": "aliexpress",

    # —ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞/–±—ã—Ç–æ–≤–∞—è
    "mvideo": "mvideo",
    "–º–≤–∏–¥–µ–æ": "mvideo",
    "eldorado": "eldorado",
    "—ç–ª—å–¥–æ—Ä–∞–¥–æ": "eldorado",
    "dns": "dns_shop",
    "–¥–Ω—Å": "dns_shop",
    "citilink": "citilink",
    "—Å–∏—Ç–∏–ª–∏–Ω–∫": "citilink",
    "svyaznoy": "svyaznoy",
    "—Å–≤—è–∑–Ω–æ–π": "svyaznoy",
    "technopark": "technopark",
    "—Ç–µ—Ö–Ω–æ–ø–∞—Ä–∫": "technopark",

    # –æ–¥–µ–∂–¥–∞/–æ–±—É–≤—å
    "lamoda": "lamoda",
    "–ª–∞ –º–æ–¥a": "lamoda",
    "asos": "asos",
    "h&m": "hm",
    "hm": "hm",

    # –µ–¥–∞/–¥–æ—Å—Ç–∞–≤–∫–∞
    "—è–Ω–¥–µ–∫—Å –µ–¥–∞": "yandex_eats",
    "yandex eats": "yandex_eats",
    "delivery club": "delivery_club",
    "–¥–µ–ª–∏–≤–µ—Ä–∏ –∫–ª–∞–±": "delivery_club",
    "—Å–∞–º–æ–∫–∞—Ç": "samokat",
    "samokat": "samokat",
    "vkusvill": "vkusvill",
    "–≤–∫—É—Å–≤–∏–ª–ª": "vkusvill",
    "lenta": "lenta",
    "–ª–µ–Ω—Ç–∞": "lenta",
    "perekrestok": "perekrestok",
    "–ø–µ—Ä–µ–∫—Ä–µ—Å—Ç–æ–∫": "perekrestok",
}

POPULAR_STORES = sorted(set(STORE_ALIASES.values()))

# ---------- –ë–î ----------
_DB_CONN: Optional[sqlite3.Connection] = None
_DB_LOCK = threading.RLock()

def db() -> sqlite3.Connection:
    global _DB_CONN
    if _DB_CONN is None:
        os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
        _DB_CONN = sqlite3.connect(DB_PATH, check_same_thread=False, timeout=10.0)
        _DB_CONN.row_factory = sqlite3.Row
        with _DB_CONN:
            _DB_CONN.execute("PRAGMA journal_mode=WAL;")
            _DB_CONN.execute("PRAGMA busy_timeout=5000;")
            _DB_CONN.execute("PRAGMA synchronous=NORMAL;")
    return _DB_CONN

def init_db():
    schema = """
    CREATE TABLE IF NOT EXISTS users(
      user_id INTEGER PRIMARY KEY,
      username TEXT,
      created_at TEXT DEFAULT CURRENT_TIMESTAMP
    );
    CREATE TABLE IF NOT EXISTS subscriptions(
      user_id INTEGER PRIMARY KEY,
      status TEXT,   -- trial|active|expired
      until TEXT,    -- ISO date
      plan TEXT,     -- monthly
      updated_at TEXT DEFAULT CURRENT_TIMESTAMP
    );
    CREATE TABLE IF NOT EXISTS deals(
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      store_slug TEXT,
      title TEXT,
      description TEXT,
      url TEXT,
      coupon_code TEXT,
      price_old REAL,
      price_new REAL,
      cashback REAL,
      start_at TEXT,
      end_at TEXT,
      created_at TEXT DEFAULT CURRENT_TIMESTAMP,
      source TEXT,
      score REAL DEFAULT 0,
      hash TEXT UNIQUE
    );
    CREATE INDEX IF NOT EXISTS idx_deals_store ON deals(store_slug);
    CREATE INDEX IF NOT EXISTS idx_deals_end ON deals(end_at);
    """
    with _DB_LOCK:
        conn = db()
        conn.executescript(schema)
        conn.commit()

def _now_iso_naive_utc() -> str:
    # datetime.utcnow() ‚Äî deprec, –∏—Å–ø–æ–ª—å–∑—É–µ–º timezone-aware ‚Üí –∑–∞—Ç–µ–º –¥–µ–ª–∞–µ–º naive
    return datetime.datetime.now(datetime.timezone.utc).replace(tzinfo=None, microsecond=0).isoformat()

def upsert_user(user_id:int, username:str=""):
    with _DB_LOCK:
        conn = db()
        conn.execute(
            "INSERT OR IGNORE INTO users(user_id, username) VALUES(?,?)",
            (user_id, username or "")
        )
        conn.commit()

def get_sub(user_id:int) -> Optional[dict]:
    with _DB_LOCK:
        conn = db()
        r = conn.execute(
            "SELECT status, until FROM subscriptions WHERE user_id=?",
            (user_id,)
        ).fetchone()
        return dict(r) if r else None

def set_sub(user_id:int, status:str, until_iso:str, plan:str="monthly"):
    with _DB_LOCK:
        conn = db()
        conn.execute("""
            INSERT INTO subscriptions(user_id,status,until,plan,updated_at)
            VALUES(?,?,?,?,?)
            ON CONFLICT(user_id) DO UPDATE SET
              status=excluded.status,
              until=excluded.until,
              plan=excluded.plan,
              updated_at=excluded.updated_at
        """, (user_id, status, until_iso, plan, _now_iso_naive_utc()))
        conn.commit()

def sub_active(user_id:int) -> bool:
    sub = get_sub(user_id)
    if not sub: 
        return False
    try:
        return datetime.datetime.fromisoformat(sub["until"]) >= datetime.datetime.now(datetime.timezone.utc).replace(tzinfo=None)
    except Exception:
        return False

def grant_trial(user_id:int, days:int=TRIAL_DAYS) -> str:
    until = (datetime.datetime.now(datetime.timezone.utc).replace(tzinfo=None) + datetime.timedelta(days=days)).replace(microsecond=0).isoformat()
    set_sub(user_id, "trial", until)
    return until

def grant_month(user_id:int, months:int=1) -> str:
    until = (datetime.datetime.now(datetime.timezone.utc).replace(tzinfo=None) + datetime.timedelta(days=30*months)).replace(microsecond=0).isoformat()
    set_sub(user_id, "active", until)
    return until

def _hash_deal(url:str, title:str, code:str) -> str:
    import hashlib
    return hashlib.sha256((url + "|" + title + "|" + (code or "")).encode("utf-8")).hexdigest()

def put_deals_bulk(deals:List[Dict[str,Any]]) -> int:
    if not deals:
        return 0
    keys = ["store_slug","title","description","url","coupon_code","price_old","price_new",
            "cashback","start_at","end_at","source","score","hash"]
    qmarks = ",".join(["?"]*len(keys))
    rows = []
    for d in deals:
        d["hash"] = _hash_deal(d.get("url",""), d.get("title",""), d.get("coupon_code",""))
        rows.append([d.get(k) for k in keys])
    inserted = 0
    with _DB_LOCK:
        conn = db()
        for row in rows:
            try:
                conn.execute(f"INSERT INTO deals({','.join(keys)}) VALUES({qmarks})", row)
                inserted += 1
            except sqlite3.IntegrityError:
                pass
        conn.commit()
    return inserted

def search_deals(store_slug:str, limit:int=8) -> List[dict]:
    with _DB_LOCK:
        conn = db()
        cur = conn.execute(
            """
            SELECT * FROM deals
            WHERE store_slug=?
              AND (end_at IS NULL OR end_at >= ?)
            ORDER BY
                score DESC,
                CASE WHEN end_at IS NULL THEN 1 ELSE 0 END,
                end_at ASC,
                created_at DESC
            LIMIT ?
            """,
            (store_slug, _now_iso_naive_utc(), limit)
        )
        return [dict(r) for r in cur.fetchall()]

def cleanup_old(days:int=60):
    threshold = (datetime.datetime.now(datetime.timezone.utc).replace(tzinfo=None) - datetime.timedelta(days=days)).isoformat()
    with _DB_LOCK:
        conn = db()
        conn.execute("DELETE FROM deals WHERE (end_at IS NOT NULL AND end_at < ?) OR created_at < ?", (threshold, threshold))
        conn.commit()

# ---------- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–û–ï ----------
UA = {"User-Agent": "Mozilla/5.0 (compatible; HalyavaBot/1.2)"}

def slug_for_query(q:str) -> Optional[str]:
    q = q.strip().lower()
    return STORE_ALIASES.get(q) or (q if q in POPULAR_STORES else None)

def esc(s:str) -> str:
    return html.escape(s or "")

# ---------- –ò–ù–¢–ï–ì–†–ê–¶–ò–ò –ò–°–¢–û–ß–ù–ò–ö–û–í ----------
# 1) Admitad Coupons API
_admitad_cached_token: Dict[str, Any] = {"value": ADMITAD_ACCESS_TOKEN, "exp": 0}

def admitad_get_token() -> Optional[str]:
    # –µ—Å–ª–∏ —Ç–æ–∫–µ–Ω —É–∂–µ –µ—Å—Ç—å –∏ –µ—â—ë –Ω–µ –∏—Å—Ç—ë–∫ ‚Äî –æ—Ç–¥–∞–¥–∏–º
    if _admitad_cached_token["value"] and _admitad_cached_token["exp"] > time.time():
        return _admitad_cached_token["value"]

    if ADMITAD_ACCESS_TOKEN:
        # —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π —Ç–æ–∫–µ–Ω –∏–∑ ENV (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ–ª—É—á–µ–Ω–Ω—ã–π –≤—Ä—É—á–Ω—É—é) ‚Äî –∫—ç—à–∏—Ä—É–µ–º –Ω–∞ —á–∞—Å
        _admitad_cached_token["value"] = ADMITAD_ACCESS_TOKEN
        _admitad_cached_token["exp"] = time.time() + 3600
        return _admitad_cached_token["value"]

    # –∏–Ω–∞—á–µ –ø—Ä–æ–±—É–µ–º client_credentials
    if not (ADMITAD_CLIENT_ID and ADMITAD_CLIENT_SECRET):
        return None
    try:
        resp = requests.post(
            "https://api.admitad.com/token/",
            data={"grant_type": "client_credentials", "scope": "coupons"},
            auth=(ADMITAD_CLIENT_ID, ADMITAD_CLIENT_SECRET),
            timeout=20
        )
        resp.raise_for_status()
        data = resp.json()
        token = data.get("access_token")
        ttl = data.get("expires_in", 3600)
        if token:
            _admitad_cached_token["value"] = token
            _admitad_cached_token["exp"] = time.time() + max(300, int(ttl) - 60)
            return token
    except Exception as e:
        log.warning("[ADMITAD] token error: %s", e)
    return None

def pull_admitad() -> int:
    if not ADMITAD_WEBSITE_ID:
        return 0
    token = admitad_get_token()
    if not token:
        return 0
    url = f"https://api.admitad.com/coupons/website/{ADMITAD_WEBSITE_ID}/"
    params = {
        "limit": 500,
        "language": "ru",
        "region": "RU",
        "status": "active",
        "ordering": "-date_end"
    }
    headers = {"Authorization": f"Bearer {token}"}
    added = 0
    try:
        log.info("[SRC][ADMITAD] %s", url)
        r = requests.get(url, headers=headers, params=params, timeout=30)
        r.raise_for_status()
        js = r.json()
        results = js.get("results") or js.get("results", [])
        out = []
        for it in results or []:
            # –≤–∞–∂–Ω—ã–µ –ø–æ–ª—è –≤ –≤—ã–¥–∞—á–µ coupons/website: campaign, promocode, date_start, date_end, short_name/description
            campaign = (it.get("campaign") or {}).get("name") or ""
            code = it.get("promocode") or ""
            title = it.get("short_name") or it.get("code") or campaign
            desc = it.get("description") or ""
            start_at = it.get("date_start")
            end_at = it.get("date_end")
            link = it.get("tracked_link") or it.get("goto_link") or it.get("link") or ""
            # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –º–∞–≥–∞–∑–∏–Ω
            store_slug = None
            c = campaign.lower()
            for k, v in STORE_ALIASES.items():
                if k in c:
                    store_slug = v
                    break
            if not store_slug:
                # fallback: –±–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ –∫–∞–º–ø–∞–Ω–∏–∏ –∫–∞–∫ slug
                store_slug = re.sub(r"[^a-z0-9]+", "_", campaign.lower()).strip("_") or "unknown"

            score = 1.0
            if code:
                score += 0.5
            if end_at:
                score += 0.2

            out.append(dict(
                store_slug=store_slug,
                title=title,
                description=desc,
                url=link,
                coupon_code=code,
                price_old=None,
                price_new=None,
                cashback=None,
                start_at=start_at,
                end_at=end_at,
                source="admitad",
                score=score
            ))
        added += put_deals_bulk(out)
    except Exception as e:
        log.error("[ADMITAD] error: %s", e)
    return added

# 2) CityAds –∫—É–ø–æ–Ω-—Ñ–∏–¥ (JSON –∏–ª–∏ XML)
def pull_cityads() -> int:
    if not CITYADS_COUPONS_URL:
        return 0
    try:
        log.info("[SRC][CITYADS] %s", CITYADS_COUPONS_URL)
        r = requests.get(CITYADS_COUPONS_URL, timeout=30, headers=UA)
        r.raise_for_status()
        added = 0
        out: List[Dict[str,Any]] = []

        content_type = r.headers.get("Content-Type","").lower()
        if "json" in content_type or CITYADS_COUPONS_URL.endswith(".json"):
            data = r.json()
            items = data.get("coupons") or data.get("items") or data
            for it in items:
                store = (it.get("campaign") or it.get("advertiser") or {}).get("name") or it.get("shop") or ""
                code = it.get("code") or it.get("coupon") or ""
                title = it.get("title") or it.get("name") or store
                desc = it.get("description") or ""
                link = it.get("url") or it.get("link") or ""
                start_at = it.get("start_date") or it.get("start") or None
                end_at = it.get("end_date") or it.get("end") or None
                store_slug = None
                s = (store or "").lower()
                for k, v in STORE_ALIASES.items():
                    if k in s:
                        store_slug = v
                        break
                if not store_slug:
                    store_slug = re.sub(r"[^a-z0-9]+","_", s).strip("_") or "unknown"

                out.append(dict(
                    store_slug=store_slug,
                    title=title,
                    description=desc,
                    url=link,
                    coupon_code=code,
                    price_old=None, price_new=None, cashback=None,
                    start_at=start_at, end_at=end_at,
                    source="cityads",
                    score=0.9 + (0.4 if code else 0)
                ))
        else:
            # XML ‚Üí feedparser (–∫–∞–∫ RSS)
            feed = feedparser.parse(r.text)
            for e in feed.entries:
                title = (e.get("title") or "").strip()
                link = e.get("link") or ""
                summary = (e.get("summary") or "").strip()
                code_match = re.search(r"(?:promo|–∫–æ–¥|code)\s*[:\- ]\s*([A-Z0-9\-]{4,16})", summary, re.IGNORECASE)
                code = code_match.group(1) if code_match else ""
                store_slug = "unknown"
                for k, v in STORE_ALIASES.items():
                    if k in (title + " " + summary).lower():
                        store_slug = v
                        break
                out.append(dict(
                    store_slug=store_slug,
                    title=title,
                    description=summary,
                    url=link,
                    coupon_code=code,
                    price_old=None, price_new=None, cashback=None,
                    start_at=None, end_at=None,
                    source="cityads_rss",
                    score=0.7 + (0.3 if code else 0)
                ))
        added += put_deals_bulk(out)
        return added
    except Exception as e:
        log.error("[CITYADS] error: %s", e)
        return 0

# 3) –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–º–æ-—Å—Ç—Ä–∞–Ω–∏—Ü—ã (–ø—Ä–æ—Å—Ç–æ–π HTML)
def pull_official_pages() -> int:
    if not OFFICIAL_PROMO_PAGES:
        return 0
    total = 0
    out: List[Dict[str,Any]] = []
    for url in OFFICIAL_PROMO_PAGES:
        try:
            log.info("[SRC][PROMO_PAGE] %s", url)
            r = requests.get(url, timeout=20, headers=UA)
            r.raise_for_status()
            soup = BeautifulSoup(r.text, "html.parser")

            # –æ–±—â–∏–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏: ¬´–ø—Ä–æ–º–æ–∫–æ–¥¬ª, ¬´–≤–≤–µ–¥–∏—Ç–µ –∫–æ–¥¬ª, ¬´–∫–æ–¥: XXXX¬ª
            texts = soup.get_text(" ", strip=True)
            for m in re.finditer(r"(?:–ø—Ä–æ–º–æ–∫–æ–¥|–∫–æ–¥)\s*[:\- ]\s*([A-Z0-9\-]{4,16})", texts, re.IGNORECASE):
                code = m.group(1)
                title = "–ü—Ä–æ–º–æ–∫–æ–¥"
                desc = "–û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –ø—Ä–æ–º–æ-—Å—Ç—Ä–∞–Ω–∏—Ü–∞"
                # –ø–æ–ø—ã—Ç–∞–µ–º—Å—è —É–≥–∞–¥–∞—Ç—å –º–∞–≥–∞–∑–∏–Ω –ø–æ –¥–æ–º–µ–Ω—É
                host = re.sub(r"^https?://", "", url)
                host = host.split("/")[0].lower()
                store_slug = "unknown"
                for k, v in STORE_ALIASES.items():
                    if k in host or k.replace(" ", "") in host:
                        store_slug = v
                        break
                out.append(dict(
                    store_slug=store_slug,
                    title=title,
                    description=desc,
                    url=url,
                    coupon_code=code,
                    price_old=None, price_new=None, cashback=None,
                    start_at=None, end_at=None,
                    source="official_page",
                    score=0.6
                ))
        except Exception as e:
            log.warning("[PROMO_PAGE] %s error: %s", url, e)
    total += put_deals_bulk(out)
    return total

# ---------- –°–ë–û–† –ò–°–¢–û–ß–ù–ò–ö–û–í ----------
def run_all_sources() -> int:
    total = 0
    total += pull_admitad()
    total += pull_cityads()
    total += pull_official_pages()
    log.info("[SCRAPE] total added: %s", total)
    return total

# ---------- –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê ----------
def fmt_deal(d:dict) -> str:
    lines = []
    lines.append(f"üõç {esc(d.get('store_slug') or '–º–∞–≥–∞–∑–∏–Ω')} ‚Äî {esc(d.get('title') or '')}")
    code = d.get("coupon_code")
    if code:
        lines.append(f"–ü—Ä–æ–º–æ–∫–æ–¥: <code>{esc(code)}</code>")
    if d.get("price_new"):
        if d.get("price_old"):
            lines.append(f"–¶–µ–Ω–∞: {d['price_new']} (–±—ã–ª–æ {d['price_old']})")
        else:
            lines.append(f"–¶–µ–Ω–∞: {d['price_new']}")
    if d.get("cashback"):
        lines.append(f"–ö—ç—à–±—ç–∫: {d['cashback']}")
    if d.get("end_at"):
        lines.append(f"–î–µ–π—Å—Ç–≤—É–µ—Ç –¥–æ: {esc(d['end_at'])}")
    if d.get("description"):
        # –∫–æ—Ä–æ—Ç–∫–æ
        desc = (d["description"] or "")
        if len(desc) > 160:
            desc = desc[:157] + "‚Ä¶"
        lines.append(esc(desc))
    if d.get("url"):
        lines.append(f"üîó {esc(d['url'])}")
    return "\n".join(lines)

# ---------- –ë–û–¢ ----------
router = Router()

@router.message(Command("start"))
async def cmd_start(m: Message):
    log.info("[START] from=%s @%s", m.from_user.id, m.from_user.username)
    upsert_user(m.from_user.id, m.from_user.username or "")
    sub = get_sub(m.from_user.id)
    if not sub:
        till = grant_trial(m.from_user.id, TRIAL_DAYS)
        await m.answer(
            f"–ü—Ä–∏–≤–µ—Ç! –í–∫–ª—é—á–∏–ª –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç—Ä–∏–∞–ª –¥–æ {esc(till)}.\n"
            f"–ö–æ–º–∞–Ω–¥—ã: /search <–º–∞–≥–∞–∑–∏–Ω>, /stores, /profile, /buy, /redeem <–∫–æ–¥>, /help",
            disable_web_page_preview=True
        )
    else:
        await m.answer("–°–Ω–æ–≤–∞ –∑–¥–µ—Å—å! –ü–æ–ø—Ä–æ–±—É–π: <code>/search ozon</code>", disable_web_page_preview=True)

@router.message(Command("help"))
async def cmd_help(m: Message):
    await m.answer(
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "‚Ä¢ /search <–º–∞–≥–∞–∑–∏–Ω> ‚Äî –Ω–∞–π—Ç–∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –ø—Ä–æ–º–æ\n"
        "‚Ä¢ /stores ‚Äî —Å–ø–∏—Å–æ–∫ –º–∞–≥–∞–∑–∏–Ω–æ–≤\n"
        "‚Ä¢ /profile ‚Äî —Å—Ç–∞—Ç—É—Å –ø–æ–¥–ø–∏—Å–∫–∏\n"
        f"‚Ä¢ /buy ‚Äî –æ—Ñ–æ—Ä–º–∏—Ç—å –ø–æ–¥–ø–∏—Å–∫—É ({MONTHLY_PRICE_RUB}‚ÇΩ/–º–µ—Å)\n"
        "‚Ä¢ /redeem <–∫–æ–¥> ‚Äî –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–º–æ–∫–æ–¥ –ø–æ–¥–ø–∏—Å–∫–∏\n"
        "‚Ä¢ /update ‚Äî –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–¥–ª—è –∞–¥–º–∏–Ω–∞)\n",
        disable_web_page_preview=True
    )

@router.message(Command("stores"))
async def cmd_stores(m: Message):
    await m.answer("–ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–∞–≥–∞–∑–∏–Ω—ã:\n" + "\n".join("‚Ä¢ " + s for s in POPULAR_STORES))

@router.message(Command("profile"))
async def cmd_profile(m: Message):
    sub = get_sub(m.from_user.id)
    if not sub:
        return await m.answer("–°—Ç–∞—Ç—É—Å: –Ω–µ—Ç –ø–æ–¥–ø–∏—Å–∫–∏. /buy ‚Äî –æ—Ñ–æ—Ä–º–∏—Ç—å (249‚ÇΩ/–º–µ—Å).")
    await m.answer(f"–°—Ç–∞—Ç—É—Å: {esc(sub['status'])} –¥–æ {esc(sub['until'])}")

@router.message(Command("buy"))
async def cmd_buy(m: Message):
    await m.answer(
        f"–ü–æ–¥–ø–∏—Å–∫–∞ {MONTHLY_PRICE_RUB}‚ÇΩ/–º–µ—Å.\n"
        f"–ù–∞ MVP –¥–æ—Å—Ç—É–ø–Ω–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏—è —á–µ—Ä–µ–∑ –ø—Ä–æ–º–æ–∫–æ–¥ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞: /redeem –ö–û–î.\n"
        f"–ü–æ–∑–∂–µ –ø—Ä–∏–∫—Ä—É—Ç–∏–º –æ–ø–ª–∞—Ç—É.",
        disable_web_page_preview=True
    )

@router.message(Command("redeem"))
async def cmd_redeem(m: Message):
    parts = (m.text or "").split(maxsplit=1)
    if len(parts) < 2 or not parts[1].strip():
        return await m.answer("–§–æ—Ä–º–∞—Ç: <code>/redeem –ö–û–î</code>")
    code = parts[1].strip()
    # –Ω–∞ MVP –∞–∫—Ç–∏–≤–∏—Ä—É–µ–º –º–µ—Å—è—Ü –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ ‚Äî –º–æ–∂–µ—à—å –ø–æ—Ç–æ–º —Å–≤–µ—Ä—è—Ç—å —Å ENV —Å–ø–∏—Å–∫–æ–º
    until = grant_month(m.from_user.id, 1)
    await m.answer(f"–ü–æ–¥–ø–∏—Å–∫–∞ –∞–∫—Ç–∏–≤–Ω–∞ –¥–æ {esc(until)}. /profile ‚Äî –ø—Ä–æ–≤–µ—Ä–∏—Ç—å")

@router.message(Command("update"))
async def cmd_update(m: Message):
    # –ø—Ä–æ—Å—Ç–æ–π ¬´–∞–¥–º–∏–Ω¬ª: —Ä–∞–∑—Ä–µ—à–∏–º –≤—Å–µ–º, –Ω–æ –ø–æ—Å—Ç–∞–≤–∏–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ —á–∞—Å—Ç–æ—Ç–µ
    await m.answer("–ü–æ—à—ë–ª —Å–±–æ—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤‚Ä¶")
    added = run_all_sources()
    await m.answer(f"–ì–æ—Ç–æ–≤–æ. –î–æ–±–∞–≤–ª–µ–Ω–æ: {added}")

@router.message(Command("search"))
async def cmd_search(m: Message):
    log.info("[SEARCH] from=%s text=%r", m.from_user.id, m.text)
    args = (m.text or "").split()[1:]
    if not args:
        # –í–ê–ñ–ù–û: –±–µ–∑ HTML-—É–≥–ª–æ–≤—ã—Ö —Å–∫–æ–±–æ–∫, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –æ—à–∏–±–∫–∏ parse entities
        return await m.answer("–§–æ—Ä–º–∞—Ç: /search –º–∞–≥–∞–∑–∏–Ω\n–ü—Ä–∏–º–µ—Ä: /search ozon")

    if not sub_active(m.from_user.id):
        return await m.answer("–ù—É–∂–Ω–∞ –∞–∫—Ç–∏–≤–Ω–∞—è –ø–æ–¥–ø–∏—Å–∫–∞. /buy ‚Äî –æ—Ñ–æ—Ä–º–∏—Ç—å (–µ—Å—Ç—å –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç—Ä–∏–∞–ª –≤ /start)")

    store_slug = slug_for_query(" ".join(args))
    if not store_slug:
        return await m.answer("–ù–µ —É–∑–Ω–∞–ª –º–∞–≥–∞–∑–∏–Ω. –ü–æ—Å–º–æ—Ç—Ä–∏ /stores –∏ –ø–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.")

    results = search_deals(store_slug, limit=8)
    if not results:
        await m.answer("–ü–æ —ç—Ç–æ–º—É –º–∞–≥–∞–∑–∏–Ω—É –ø–æ–∫–∞ –ø—É—Å—Ç–æ. –ó–∞–ø—Ä–∞—à–∏–≤–∞—é –∏—Å—Ç–æ—á–Ω–∏–∫–∏‚Ä¶")
        # —Ñ–æ—Ä—Å-—Å–±–æ—Ä –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞ (–ø–æ–∫–∞ —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ)
        run_all_sources()
        results = search_deals(store_slug, limit=8)
        if not results:
            return await m.answer("–ü–æ–∫–∞ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏. –ó–∞–≥–ª—è–Ω–∏ –ø–æ–∑–∂–µ –∏–ª–∏ –ø–æ–ø—Ä–æ–±—É–π –¥—Ä—É–≥–æ–π –º–∞–≥–∞–∑–∏–Ω.")

    for d in results:
        try:
            await m.answer(fmt_deal(d), disable_web_page_preview=True)
        except Exception:
            # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –æ—Ç–ø—Ä–∞–≤–∏–º –±–µ–∑ HTML
            txt = re.sub(r"<.*?>", "", fmt_deal(d))
            await m.answer(txt, disable_web_page_preview=True)

# ---------- –ü–õ–ê–ù–ò–†–û–í–©–ò–ö ----------
scheduler: Optional[AsyncIOScheduler] = None

async def scrape_job():
    try:
        added = run_all_sources()
        log.info("[SCRAPER] added: %s", added)
    except Exception as e:
        log.error("[SCRAPER] error: %s", e)

async def cleanup_job():
    try:
        cleanup_old(60)
        log.info("[CLEANUP] done")
    except Exception as e:
        log.error("[CLEANUP] error: %s", e)

async def main():
    if not BOT_TOKEN:
        raise RuntimeError("Set BOT_TOKEN env var")

    init_db()

    bot = Bot(
        token=BOT_TOKEN,
        default=DefaultBotProperties(parse_mode=ParseMode.HTML)
    )
    dp = Dispatcher()
    dp.include_router(router)

    global scheduler
    scheduler = AsyncIOScheduler(timezone=TIMEZONE)
    scheduler.add_job(scrape_job, "interval", minutes=30, id="scrape")
    scheduler.add_job(cleanup_job, "interval", hours=12, id="cleanup")
    scheduler.start()

    # –ø–µ—Ä–≤—ã–π —Å–±–æ—Ä ‚Äî —á–µ—Ä–µ–∑ 10 —Å–µ–∫, —á—Ç–æ–±—ã –±–∞–∑–∞ –Ω–µ –±—ã–ª–∞ –ø—É—Å—Ç–æ–π
    loop = asyncio.get_event_loop()
    loop.call_later(10, lambda: asyncio.create_task(scrape_job()))

    log.info("Start polling")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
